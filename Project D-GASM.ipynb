{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## ## Part 1\n",
    "## Collation\n",
    "###############\n",
    "import os\n",
    "\n",
    "x = os.listdir()\n",
    "\n",
    "AtList, BuList, OsList, PoList, ObList = [], [], [], [], []\n",
    "\n",
    "for line in x:\n",
    "    if \"Atiku\" in line:\n",
    "        AtList.append(line)\n",
    "    elif \"Buhari\" in line:\n",
    "        BuList.append(line)\n",
    "    elif \"Osinbajo\" in line:\n",
    "        OsList.append(line)\n",
    "    elif \"Peter\" in line:\n",
    "        PoList.append(line)\n",
    "    elif \"Oby\" in line:\n",
    "        ObList.append(line) \n",
    "\n",
    "All = [AtList, BuList, OsList, PoList, ObList]\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## ## Part 2\n",
    "## Data Wrangling - PoList of Part 1 in use here\n",
    "###############\n",
    "\n",
    "#Pulling juicy summary parts from json of Tweets\n",
    "import pandas\n",
    "\n",
    "name, tweet, time, location, followers, friends, status_count = [], [], [], [], [], [], []\n",
    "for item in PoList:\n",
    "    print(\"Processing \" + item + \" ...\")        \n",
    "    df = pandas.read_json(item, lines = True)\n",
    "\n",
    "    #Get Screen name\n",
    "    for line in df.user:\n",
    "        n = line.get('screen_name')\n",
    "        name.append(n)\n",
    "        \n",
    "    #Get Tweet removing all non-characters\n",
    "    for line in df.text:\n",
    "        t = str(line).lower()\n",
    "        t.replace('[^a-zA-Z]', '')\n",
    "        tweet.append(t)\n",
    "    \n",
    "    #Get time\n",
    "    for line in df.created_at:\n",
    "        time.append(line)\n",
    "    \n",
    "    #Get Location converting to lowercase\n",
    "    for line in df.user:\n",
    "        x = line.get('location')\n",
    "        x = str(x).lower()\n",
    "        location.append(x)\n",
    "\n",
    "    #Get Followers\n",
    "    for line in df.user:\n",
    "        f = line.get('followers_count')\n",
    "        followers.append(f)\n",
    "\n",
    "    #Get Friends\n",
    "    for line in df.user:\n",
    "        fr = line.get('friends_count')\n",
    "        friends.append(fr)\n",
    "\n",
    "    #Get Status count\n",
    "    for line in df.user:\n",
    "        s = line.get('statuses_count')\n",
    "        status_count.append(s)\n",
    "    print(item + \" done!\")\n",
    "\n",
    "\n",
    "#Build into a df\n",
    "TweetI = pandas.DataFrame(columns=('name','location', 'tweet','friends', 'followers', 'status_count'))\n",
    "\n",
    "TweetI[\"name\"] = name\n",
    "TweetI[\"location\"] = location\n",
    "TweetI['tweet'] = tweet\n",
    "TweetI['time'] = time\n",
    "TweetI[\"friends\"]= friends\n",
    "TweetI['followers'] = followers\n",
    "TweetI['status_count'] = status_count\n",
    "\n",
    "##Write df to csv file\n",
    "TweetI.to_csv(\"PObiJuice.csv\")\n",
    "\n",
    "##Sort_values takes 'by=' or just the column name\n",
    "## Get a summary of the juice\n",
    "loc_sum = TweetI.groupby('location').count().sort_values(by = 'name', ascending = False)\n",
    "name_sum = TweetI.groupby('name').count().sort_values(by = 'tweet', ascending = False)\n",
    "time_sum = TweetI.groupby('time').count().sort_values(\"name\", ascending = False)\n",
    "\n",
    "##Write juice summary to csv\n",
    "loc_sum.to_csv('locJuicePo.csv')\n",
    "name_sum.to_csv('nameJuicePo.csv')\n",
    "time_sum.to_csv('timeJuicePo.csv')\n",
    "\n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## ## Part 3\n",
    "## Sentiment Analysis\n",
    "###############\n",
    "\n",
    "#Bring in needed libraries\n",
    "import pandas \n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "#Import formatted tweet info converted to csv\n",
    "df = pandas.read_csv(\"CandidateJuice.csv\")\n",
    "#Remove the index from the scv file\n",
    "del df[\"Unnamed: 0\"] \n",
    "\n",
    "\n",
    "#Create a new column from df.time, 'date_dym' leaving the first 9 elements and change df.time to deleting/repalcing only the first 10\n",
    "df['date_ymd'] = df.loc[:,\"time\"].map(lambda x: x.replace(x[10:], ''))\n",
    "df['time'] = df.loc[:,\"time\"].map(lambda x: x.replace(x[:11], ''))\n",
    "\n",
    "#sort by date of tweet and time columns\n",
    "TweetsByDate = df.sort_values([\"date_ymd\", \"time\"], ascending = True)\n",
    "#TweetsByDate.head()\n",
    "\n",
    "#Sentiment Analysis\n",
    "CandidateTweets = TweetsByDate.tweet\n",
    "\n",
    "#Convert tweets to lowercase\n",
    "CandidateTweets = CandidateTweets.map(lambda x: str(x).lower())\n",
    "\n",
    "#Remove non-characters from tweets\n",
    "CandidateTweets = CandidateTweets.map(lambda x: x.replace('[^a-zA-Z]', ''))\n",
    "\n",
    "theFile = CandidateTweets\n",
    "\n",
    "sentiment = []\n",
    "polarity = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "\n",
    "for tweet in theFile:\n",
    "    analysis=TextBlob(str(tweet))\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    if (analysis.sentiment.polarity == 0):\n",
    "        sentiment.append(\"neutral\")\n",
    "    elif (analysis.sentiment.polarity < 0.00):\n",
    "        sentiment.append(\"negative\")\n",
    "    elif (analysis.sentiment.polarity > 0.00):\n",
    "        sentiment.append(\"positive\")\n",
    "        \n",
    "print(\"Done Analysing sentimetns!\")\n",
    "\n",
    "#Add a column of the analysed sentiments\n",
    "TweetsByDate[\"sentiment\"] = sentiment\n",
    "\n",
    "#Sort the df into sentiment groups\n",
    "PosTweets = TweetsByDate[TweetsByDate.sentiment == 'positive']\n",
    "NegTweets = TweetsByDate[TweetsByDate.sentiment == 'negative']\n",
    "NuetTweets = TweetsByDate[TweetsByDate.sentiment == 'neutral']\n",
    "\n",
    "#Remove mentions of rival candidate from neut, pos and neg tweets write into new values\n",
    "rival = rivalName #as string\n",
    "n_PosTweets, n_NegTweets, n_NuetTweets = [], [], []\n",
    "for line in PosTweets.tweet:\n",
    "    if rival in line:\n",
    "        n_PosTweets.append(line)\n",
    "\n",
    "for line in NegTweets.tweet:\n",
    "    if rival in line:\n",
    "        n_NegTweets.append(line)\n",
    "\n",
    "for line in NuetTweets.tweet:\n",
    "    if rival in line:\n",
    "        n_NuetTweets.append(line)\n",
    "\n",
    "#rename to Cleaned\n",
    "CleanedCandidateTweets = TweetsByDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## ## Part 4\n",
    "## More Cleaning, Analysis\n",
    "###############\n",
    "\n",
    "#Prepare for state sentiments\n",
    "state = []\n",
    "state_pos = [] #neg sentiment number from states\n",
    "state_neg = [] #pos sentiment number from states\n",
    "\n",
    "print(\"states cleaning...\")\n",
    "print(\"lagos...\")\n",
    "#Change all lines of Lagos mention to lagos in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Lagos') if 'lagos' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Lagos') if 'lasgidi' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Lagos') if 'eko' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Lagos') if 'lagos, nigeria' in str(x) else str(x))\n",
    "lagos = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Lagos'].sort_values(\"sentiment\")\n",
    "posLagos = len(lagos[lagos['sentiment'] == 'positive'])\n",
    "negLagos = len(lagos[lagos['sentiment'] == 'negative'])\n",
    "state.append(\"Lagos\")\n",
    "state_pos.append(str(posLagos))\n",
    "state_neg.append(str(negLagos))\n",
    "\n",
    "print(\"abuja...\")\n",
    "#Change all lines of abuja mention to abuja in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Abuja') if 'abuja' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Abuja') if 'fct' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Abuja') if 'abuja, nigeria' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Abuja') if 'fct, nigeria' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Abuja') if 'aso rock' in str(x) else str(x))\n",
    "abuja = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Abuja'].sort_values(\"sentiment\")\n",
    "posAbuja = len(abuja[abuja['sentiment'] == 'positive'])\n",
    "negAbuja = len(abuja[abuja['sentiment'] == 'negative'])\n",
    "state.append(\"Abuja\")\n",
    "state_pos.append(str(posAbuja))\n",
    "state_neg.append(str(negAbuja))\n",
    "\n",
    "print(\"kano...\")\n",
    "#Change all lines of kano mention to kano in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Kano') if 'kano' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Kano') if 'kano, nigeria' in str(x) else str(x))\n",
    "kano = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Kano'].sort_values(\"sentiment\")\n",
    "posKano = len(kano[kano['sentiment'] == 'positive'])\n",
    "negKano = len(kano[kano['sentiment'] == 'negative'])\n",
    "state.append(\"Kano\")\n",
    "state_pos.append(str(posKano))\n",
    "state_neg.append(str(negKano))\n",
    "\n",
    "print(\"katsina...\")\n",
    "#Change all lines of katsina mention to katsina in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Katsina') if 'katsina' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Katsina') if 'katsina, nigeria' in str(x) else str(x))\n",
    "katsina = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Katsina'].sort_values(\"sentiment\")\n",
    "posKatsina = len(katsina[katsina['sentiment'] == 'positive'])\n",
    "negKatsina = len(katsina[katsina['sentiment'] == 'negative'])\n",
    "state.append(\"Katsina\")\n",
    "state_pos.append(str(posKatsina))\n",
    "state_neg.append(str(negKatsina))\n",
    "\n",
    "print(\"adamawa...\")\n",
    "#Change all lines of adamawa mention to adamawa in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Adamawa') if 'adamawa' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Adamawa') if 'adamawa, nigeria' in str(x) else str(x))\n",
    "adamawa = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Adamawa'].sort_values(\"sentiment\")\n",
    "posAdamawa = len(adamawa[adamawa['sentiment'] == 'positive'])\n",
    "negAdamawa = len(adamawa[adamawa['sentiment'] == 'negative'])\n",
    "state.append(\"Adamawa\")\n",
    "state_pos.append(str(posAdamawa))\n",
    "state_neg.append(str(negAdamawa))\n",
    "\n",
    "print(\"anambra...\")\n",
    "#Change all lines of Anambra mention to Anambra in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Anambra') if 'anambra' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Anambra') if 'nnewi' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Anambra') if 'awka' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Anambra') if 'onitsha' in str(x) else str(x))\n",
    "anambra = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Anambra'].sort_values(\"sentiment\")\n",
    "posAnambra = len(anambra[anambra['sentiment'] == 'positive'])\n",
    "negAnambra = len(anambra[anambra['sentiment'] == 'negative'])\n",
    "state.append(\"Anambra\")\n",
    "state_pos.append(str(posAnambra))\n",
    "state_neg.append(str(negAnambra))\n",
    "\n",
    "print(\"enugu...\")\n",
    "#Try to get all Enugu\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Enugu') if 'enugu' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Enugu') if '042' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Enugu') if 'enugu, nigeria' in str(x) else str(x))\n",
    "enugu = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Enugu'].sort_values(\"sentiment\")\n",
    "posEnugu = len(enugu[enugu['sentiment'] == 'positive'])\n",
    "negEnugu = len(enugu[enugu['sentiment'] == 'negative'])\n",
    "state.append(\"Enugu\")\n",
    "state_pos.append(str(posEnugu))\n",
    "state_neg.append(str(negEnugu))\n",
    "\n",
    "print(\"rivers...\")\n",
    "#Change all lines of PH mention to PH in location\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Rivers') if 'ph' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Rivers') if 'port harcourt' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'Rivers') if 'portharcourt' in str(x) else str(x))\n",
    "rivers = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'Rivers'].sort_values(\"sentiment\")\n",
    "posRivers = len(rivers[rivers['sentiment'] == 'positive'])\n",
    "negRivers = len(rivers[rivers['sentiment'] == 'negative'])\n",
    "state.append(\"Rivers\")\n",
    "state_pos.append(str(posRivers))\n",
    "state_neg.append(str(negRivers))\n",
    "\n",
    "print(\"uk...\")\n",
    "#Try to get all UK\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'UK') if 'london' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'UK') if 'london, uk' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'UK') if 'london, england' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'UK') if 'uk' in str(x) else str(x))\n",
    "CleanedCandidateTweets[\"location\"] = CleanedCandidateTweets[\"location\"].map(lambda x: x.replace(x, 'UK') if 'united kingdom' in str(x) else str(x))\n",
    "uk = CleanedCandidateTweets[CleanedCandidateTweets['location'] == 'UK'].sort_values(\"sentiment\")\n",
    "posUK = len(uk[uk['sentiment'] == 'positive'])\n",
    "negUK = len(uk[uk['sentiment'] == 'negative'])\n",
    "state.append(\"UK\")\n",
    "state_pos.append(str(posUK))\n",
    "state_neg.append(str(negUK))\n",
    "print(\"states done!\")\n",
    "\n",
    "print(\"creating table of sentiments...\")\n",
    "#Create a table of sentiments by states\n",
    "SentimentStates = pandas.DataFrame(columns = [\"state\", \"positive\", \"negative\"])\n",
    "SentimentStates[\"state\"] = state\n",
    "SentimentStates[\"positive\"] = state_pos\n",
    "SentimentStates[\"negative\"] = state_neg\n",
    "print(\"done!\")\n",
    "\n",
    "\n",
    "print(\"writing data to excel...\")\n",
    "#Write to excel\n",
    "from pandas import ExcelWriter\n",
    "writer = ExcelWriter('CandidateSummary.xlsx')\n",
    "lagos.to_excel(writer,'lagos')\n",
    "abuja.to_excel(writer,'abuja')\n",
    "kano.to_excel(writer,'kano')\n",
    "enugu.to_excel(writer,'enugu')\n",
    "uk.to_excel(writer,'uk')\n",
    "katsina.to_excel(writer,'katsina')\n",
    "anambra.to_excel(writer,'anambra')\n",
    "adamawa.to_excel(writer,'adamawa')\n",
    "rivers.to_excel(writer,'rivers')\n",
    "SentimentStates.to_excel(writer, 'SentimentStates')\n",
    "\n",
    "writer.save()\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## ## Part 5\n",
    "## Pie Plot for general overview\n",
    "###############\n",
    "\n",
    "#Data to plot\n",
    "labels = 'positive', 'negative'\n",
    "sizes = [len(PosTweets), len(NegTweets)]\n",
    "colors = ['green', 'red']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "\n",
    "#Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title(\"Sentiment Analysis for \" + \"Candidate\" + \"\\n\" + \"with a total of \" + str(len(theFile)) +\" \" + \"tweets\")\n",
    "plt.show()\n",
    "\n",
    "#After opponent weeding\n",
    "#Data to plot\n",
    "labels = 'positive', 'negative'\n",
    "sizes = [(len(PosTweets)-len(n_PosTweets)), (len(NegTweets)-len(n_NegTweets))]\n",
    "colors = ['green', 'red']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "\n",
    "#Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title(\"Sentiment Analysis for \" + \"Candidate\" + \"\\n\" + \"with a total of \" + str(len(theFile)) +\" \" + \"tweets\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
